{
    "questions": [
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 1 - Randomly!",
            "question": "What the most efficient service can integrate data files from its on-premises with AWS Cloud via an NFS interface?",
            "answer": "Storage Gateway - File Gateway.",
            "srcImg": "",
            "descriptionP": "AWS Storage Gateway's file interface, or file gateway, offers you a seamless way to connect to the cloud in order to store application data files and backup images as durable objects on Amazon S3 cloud storage. File gateway offers SMB or NFS-based access to data in Amazon S3 with local caching."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 2 - Randomly!",
            "question": "What feature of an Amazon S3 bucket only be suspended and not disabled once it have been enabled?",
            "answer": "Versioning.",
            "srcImg": "",
            "descriptionP": "Once you version-enable a bucket, it can never return to an unversioned state. Versioning can only be suspended once it has been enabled."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 3 - Randomly!",
            "question": "Massive volumes of data that can be divided into two categories. The 'hot data' need to be both processed and stored quickly in a parallel and distributed fashion. The 'cold data need to be kept for reference with quick access for reads and updates at a low cost. What AWS services is BEST suited to accelerate the process?",
            "answer": "Amazon FSx for Lustre.",
            "srcImg": "",
            "descriptionP": "FSx for Lustre provides the ability to both process the 'hot data' in a parallel and distributed fashion as well as easily store the 'cold data' on Amazon S3."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 4 - Randomly!",
            "question": "A company utilizes User Datagram Protocol and needs to support fast regional failover in case an AWS Region goes down. The company wants to continue using its own custom Domain Name System (DNS) service. What AWS service represent the best solution?",
            "answer": "Global Accelerator.",
            "srcImg": "",
            "descriptionP": "AWS Global Accelerator improves performance for a wide range of applications over TCP or UDP by proxying packets at the edge to applications running in one or more AWS Regions. Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or voice over IP, as well as for HTTP use cases that specifically require static IP addresses or deterministic, fast regional failover."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 5 - Randomly!",
            "question": "A company has a web application that runs 24*7 in the production environment. The company runs a clone of the same application in the dev environment for up to 8 hours every day. The company wants to build the MOST cost-optimal solution by deploying these applications using the best-fit pricing options for EC2 instances. What would you recommend?",
            "answer": "Use EC2 reserved instance for the production and on-demand instances for the dev.",
            "srcImg": "",
            "descriptionP": "For the given use case, you can use Amazon EC2 Reserved Instances for the prodution application as it is run 24*7; This way you can get a 72% discount if you avail a 3-year term. You can use on-demand instances for the dev application since it is only used for up to 8 hours per day. On-demand offers the flexibility to only pay for the Amazon EC2 instance when it is being used (0 to 8 hours for the given use case)."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 6 - Randomly!",
            "question": "A market need to support both stateful and stateless client-server communications via the application programming interface (APIs) developed using its platform. You have been hired by the startup to build a solution to fulfill this market need using Amazon API Gateway.",
            "answer": "Amazon API Gateway creates RESTful APIs that enable stateless client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, full duplex communication between client and server.",
            "srcImg": "",
            "descriptionP": "Amazon API Gateway creates RESTful APIs that: are HTTP-based. Enable stateless client-server communication. Implement standard HTTP methos such as GET, POST, PUT, PATCH, and DELETE. Also, Amazon API Gateway creates WebSocket APIs that: adhere to the WebSocket protocol, which enables stateful, full-duplex communication between client and server. Route incoming messages based on message content. So Amazon API Gateway supports stateless RESTful APIs as well as stateful WebSocket APIs."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 7 - Randomly!",
            "question": "Amazon SQS is used for migrate several core applications to the cloud to ensure high availability and cost efficiency. The development team expects a peak rate of about 1000 messages per second to be processed via SQS. It is important that the messages are processed in order. Which option can be used to implement this system?",
            "answer": "SQS FIFO (Fist-In-Fist-Out) queue in batch mode of 4 messages per operation to process the messages at the peak rate.",
            "srcImg": "",
            "descriptionP": "By default, FIFO queues support up to 300 messages per second (300 send, receive, or delete operations per second). When you batch 10 messages per operation (maximum), FIFO queues can support up to 3,000 messages per second. Therefore you need to process 4 messages per operations so that the FIFO queue can support up to 1200 messages per second, which is well within the peak rate."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 8 - Randomly!",
            "question": "An EC2 instance 1A is running in AWS Region A. Later, it was created a new Amazon Machine Image (AMI) in Region A from a snapshot. This AMI is then copied into another Region B. It was provisioned an instance 1B in Region B using this new AMI in Region B. What entities exist in Region B?",
            "answer": "1 EC2 instance, 1 AMI and 1 snapshot exist in Region B.",
            "srcImg": "",
            "descriptionP": "An AMI provides the information required to launch an instance. You must specify an AMI when you launch an instance. When the new AMI is copied from Region A into Region B, it automatically creates a snapshot in Region B because AMIs are based on the underlying snapshots. Further, an instance is created from this AMI in Region B. Hence, we have 1 EC2, 1AMI and 1 snapshot in Region B."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 9 - Randomly!",
            "question": "A Fleet of EC2 instances realized a specialized task that must deliver high random I/O performance. Each instance in the fleet would have access to a dataset that is replicated across the instances by the application itself. Because of the resilient application architecture, the specialized task would continue to be processed even if any instance goes down, as the underlying application would ensure the replacement instance has access to the required dataset. Which of the following options is the MOST cost-optimal and resource-efficient solution to build this fleet of EC2 instances?",
            "answer": "Use Instance Store based EC2 instances.",
            "srcImg": "",
            "descriptionP": "An instance store provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host instance. Instance store is ideal for the temporary storage of information that changes frequently such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers. Instance store volumes are included as part of the instance's usage cost. As Instance Store based volumes provide high random I/O performance at low cost (as the storage is part of the instance's usage cost) and the resilient architecture can adjust for the loss of any instance, therefore you should use Instance Store based EC2 instances for this use-case."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 10 - Randomly!",
            "question": "Multiple microservices running on EC2 instances under an ALB. The team wants ti route traffic to multiple back-end services based on the URL path of the HTTP header. So it wants request for https://www.test.com/orders to go to a specific microservice and request for https://www.test.com/products to go to another microservice. Which of the following features of ALB can be used?",
            "answer": "Path-based Routing.",
            "srcImg": "",
            "descriptionP": "Path-based Routing: you can route a client request based on the URL path of the HTTP header. You can use path conditions to define rules that route request based on the URL in the request (also known as path-based routing). The path pattern is applied only to the URL, not to its query parameters."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 11 - Randomly!",
            "question": "A dynamic website is hosted using on-premises servers in its data center in the USA. The company is lauching its website in ASIA, and it wants to optimize the website loading times for new users in ASIA. The website's backend must remain in the USA. The website is being launched in a few days, and an immediate solutions is needed. What would you recommend?",
            "answer": "Use CloudFront with a custom origin pointing to the on-premises servers.",
            "srcImg": "",
            "descriptionP": "CloudFront is a web service that gives businesses and web application developers an easy cost-effective way to distribute content with low latency and high data transfer speeds. CloudFront uses standard cache control headers you set on your files to identify static and dynamic content. You can use different origins for different types of content on a single site - e.g. S3 for static objects, EC2 for dynamic content, and custom origins for third-party content. An origin server stores the original, definitive version of your objects. If you're serving content over HTTP, your origin server is either an S3 bucket or an HTTP server, such as a web server. Your HTTP server can run on an EC2 instance or on a server that you manage, these servers are also known as custom origins."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 12 - Randomly!",
            "question": "A company maintains the data for the last 100 years. The data has a velocity of 1 GB per minute. You would like to store the data with only the most relevant attributes. What AWS services would you use to build the most cost-effective solution with the LEAST amount of infrastructure maintenance?",
            "answer": "Ingest the data in Amazon Kinesis Data Firehose and use an intermediary AWS Lambda function to filter and transform the incoming stream before the output is dumped on S3.",
            "srcImg": "",
            "descriptionP": "Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. It can capture, transform, and load streaming data into S3, Amazon Redshift, Amazon OpenSearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you're already using today. It is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also batch, compress, and encrypt the data before loading it, minimizing the amount of storage used at the destination and increasing security. So, ingest the data in Amazon Kinesis Data Firehose and use a AWS Lambda function to filter and transform the incoming data before the output is dumped on S3. This way you only need to store a sliced version of the data with only the relevant data attributes required for your model. Also it should be noted that this solution is entirely serveless and requires no infrastructure maintenance."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 13 - Randomly!",
            "question": "A junior scientist is trying to upload a high-resolution image into S3. The image size is approximately 3 gigabytes. The junior scientist is using S3 Transfer Acceleration (Amazon S3TA) for faster image upload. It turns out that Amazon S3TA did not result in an accelerated transfer. Given this scenario, which of the following is correct regarding the charges for this image transfer?",
            "answer": "The junior scientist does not need to pay any transfer charges for the image upload.",
            "srcImg": "",
            "descriptionP": "There are no S3 data transfer charges when data is transferred in from the internet. Also with S3TA, you pay only for transfer that are accelerated. Therefore the junior scientist does not need to pay any transfer charges for the image upload because S3TA did not result in an accelerated transfer."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 14 - Randomly!",
            "question": "A company wants to set up an AWS cloud architecture that throttles request in case of sudden traffic spikes. The company is looking for AWS services that can be used for buffering or throttling to handle such traffic variations. Which of the following services can be used to support this requirement?",
            "answer": "Amazon API Gateway, Amazon SQS and Amazon Kinesis.",
            "srcImg": "",
            "descriptionP": "Throttling is the process of limiting the number of requests an authorized program can submit to a given operation in a given amount of time. To prevent your API from being overwhelmed by too many requests, Amazon API Gateway throttles requests to your API using the token bucket algorithm, where a token counts for a request. Specifically, API Gateway sets a limit on a steady-state rate and a burst of request submissions against all APIs in your account. In the token bucket algorithm, the burst is the maximum bucket size. SQS is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serveless applications. SQS offers buffer capabilities to smooth out temporary volume spikes without losing messages or increasing latency. Amazon Kinesis is a fully managed, scalable service that can ingest, buffer, and process streaming data in real time."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 15 - Randomly!",
            "question": "A new DevOps enginner wants to understand the replication capabilities for RDS Multi-AZ deployment as well as RDS Read-Replicas. Which of the following correctly summarizes these capabilities?",
            "answer": "Multi-AZ follows synchronous replication and spans at least two Availability Zones (AZs) within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone (AZ), Cross-AZ, or Cross-Region.",
            "srcImg": "",
            "descriptionP": "RDS Multi-AZ deployments provide enhanced availability and durability for RDS database instances, making them a natural fit for production database workloads. When you provision a Multi-AZ DB instance, RDS automatically creates a primary DB instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Multi-AZ spans at least two Availability Zones (AZs) within a single region. RDS Read Replicas provide enhanced performance and durability for RDS database instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. For the MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server database engines, RDS creates a second DB instance using a snapshot of the source DB instance. It then uses the engines' native asynchrounous replication to update the read replica whenever there is a change to the source DB instance. RDS replicates all databases in the source DB instance. Read replicas can be within an Availability Zone (AZ), Cross-AZ, or Cross-Region."
        }
    ],
    "options": [
        {
            "option1": "Storage Gateway - Volume Gateway.",
            "option2": "Site-to-Site VPN.",
            "option3": "Storage Gateway - File Gateway.",
            "option4": "Storage Gateway - Tape Gateway.",
            "option5": "Instance Store."
        },
        {
            "option1": "Requester Pays.",
            "option2": "Server Access Logging.",
            "option3": "Versioning.",
            "option4": "Policies.",
            "option5": "Static Website Hosting."
        },
        {
            "option1": "EMR.",
            "option2": "Glue.",
            "option3": "S3 Glacier Deep Archive.",
            "option4": "Amazon FSx for Windows File Server.",
            "option5": "Amazon FSx for Lustre."
        },
        {
            "option1": "CloudFront.",
            "option2": "Third-Party services.",
            "option3": "Route 53.",
            "option4": "Global Accelerator.",
            "option5": "ELB."
        },
        {
            "option1": "Use EC2 reserved instance for the production and spot instances for the dev.",
            "option2": "Use EC2 reserved instance for the production and spot block intances for the dev.",
            "option3": "Use EC2 reserved instance for the production and on-demand instances for the dev.",
            "option4": "Use only EC2 on-demand instaces for the production and dev.",
            "option5": "Use on-demand EC2 instances for the production and spot intances for the dev."
        },
        {
            "option1": "Amazon API Gateway creates RESTful APIs that enable stateful client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, full duplex communication between client and server.",
            "option2": "Amazon API Gateway creates RESTful APIs that enable stateless client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, full duplex communication between client and server.",
            "option3": "Amazon API Gateway creates RESTful APIs that enable stateless client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateless, full duplex communication between client and server.",
            "option4": "Amazon API Gateway creates RESTful APIs that enable both stateless and stateful client-server communication.",
            "option5": "Amazon API Gateway creates RESTful APIs that enable stateful client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateless, full duplex communication between client and server."
        },
        {
            "option1": "Use SQS standard queue to process the messages.",
            "option2": "SQS FIFO (First-In-First-Out) queue in batch mode of 2 messages per operation to process the messages at the peak rate.",
            "option3": "SQS FIFO (First-In-First-Out) queue to process the messages.",
            "option4": "SQS FIFO (Fist-In-Fist-Out) queue in batch mode of 4 messages per operation to process the messages at the peak rate.",
            "option5": "Use both SQS standard queue and SQS FIFO queue to process the messages."
        },
        {
            "option1": "1 EC2 instance and 1 snapshot exist in Region B.",
            "option2": "1 EC2 instance and 1 AMI exist in Region B.",
            "option3": "1 EC2 instance, 1 AMI and 2 snapshots.",
            "option4": "1 EC2 instance and 2 AMIs exist in Region B.",
            "option5": "1 EC2 instance, 1 AMI and 1 snapshot exist in Region B."
        },
        {
            "option1": "Use EBS based EC2 instances.",
            "option2": "Use EC2 instances with access to S3 based storage.",
            "option3": "Use EC2 instances with EFS mount points.",
            "option4": "Use EC2 instances with EBS and EFS mount points.",
            "option5": "Use Instance Store based EC2 instances."
        },
        {
            "option1": "Host-based Routing.",
            "option2": "Query string parameter-based routing.",
            "option3": "Path-based Routing.",
            "option4": "HTTP method-based routing.",
            "option5": "HTTP header-based routing."
        },
        {
            "option1": "Leverage a Route 53 geo-proximity routing policy pointing to on-premises servers.",
            "option2": "Migrate the website to S3. Use S3 cross-region replication (S3 CRR) between AWS Regions in the USA and ASIA.",
            "option3": "Use CloudFront with a custom origin pointing to the DNS record of the website on Route 53.",
            "option4": "Use CloudFront with a custom origin pointing to the on-premises servers.",
            "option5": "Migrate the dynamic website to EC2."
        },
        {
            "option1": "Ingest the data in Amazon Kinesis Data Firehose and use an intermediary AWS Lambda function to filter and transform the incoming stream before the output is dumped on S3.",
            "option2": "Ingest the data in a Spark Streaming Cluster on EMR and use Spark Streaming transformations before writing to S3.",
            "option3": "Ingest the data in Amazon Kinesis Data Streams and use an intermediary AWS Lambda function to filter and transform the incoming stream before the output is dumped on S3.",
            "option4": "Ingest the data in Amazon Kinesis Data Analytics and use Amazon Kinesis Data Firehose to filter and transform the data before the output is dumped on S3.",
            "option5": "Ingest the data in Amazon Kinesis Data Analytics and use SQL queries to filter and transform the data before writing to S3."
        },
        {
            "option1": "The junior scientist needs to pay both S3 transfer charges and S3TA transfer charges for the image upload.",
            "option2": "The junior scientist only needs to pay S3 transfer charges for the image upload.",
            "option3": "The junior scientist does not need to pay any transfer charges for the image upload.",
            "option4": "The junior scientist needs to pay size image, S3 transfer charges and S3TA transfer charges for the image upload.",
            "option5": "The junior scientist only needs to pay S3TA transfer charges for the image upload."
        },
        {
            "option1": "Amazon SQS, Amazon SNS and AWS Lambda.",
            "option2": "Amazon API Gateway, Amazon SQS and Amazon Kinesis.",
            "option3": "Amazon Gateway Endpoints, Amazon SNS and AWS Lambda.",
            "option4": "Amazon Gateway Endpoints, Amazon SQS and Amazon Kinesis.",
            "option5": "Elastic Load Balancer, Amazon SQS and AWS Lambda."
        },
        {
            "option1": "Multi-AZ follows synchronous replication and spans at least two Availability Zones (AZs) within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone (AZ), Cross-AZ, or Cross-Region.",
            "option2": "Multi-AZ follows synchronous replication and spans at least two regions. Read replicas follow synchronous replication and can be within an Availability Zone (AZ), Cross-AZ, or Cross-Region.",
            "option3": "Multi-AZ follows asynchronous replication and spans one Availability Zone (AZ) within a single region. Read replicas follow synchronous replication and can be within an Availability Zone (AZ), Cross-AZ, or Cross-Region.",
            "option4": "Multi-AZ follows asynchronous replication and spans at least two Availability Zones (AZs) within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone (AZ), Cross-AZ, or Cross-Region.",
            "option5": "Multi-AZ follows asynchronous replication and spans at least two Availability Zone (AZs) within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone (AZ), Cross-AZ, or Cross-Region."
        }
    ],
    "multiQuestions": [
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 1 - Randomly!",
            "question": "About S3, the developers were asked to identify the invalid storage class lifecycle transitions for objects stored on S3. Can you spot the INVALID lifecycle transitions from the options below? Select two.",
            "answer": "true",
            "answerText": "Amazon S3 Intelligent-Tiering => Amazon S3 Standard // Amazon S3 One Zone-IA => Amazon S3 Standard-IA",
            "srcImg": "",
            "descriptionP": "Following are the unsupported life cycle transitions for S3 storage classes, any storage class to the S3 Standard storage class. S3 Intelligent-Tiering storage class to the S3 Standard-IA storage class. S3 One Zone-IA storage class to the S3 Standard-IA or S3 Intelligent-Tiering storage classes."
        }, 
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 2 - Randomly!",
            "question": "E-commerce company is documenting the process flow to provision EC2 via the Amazon EC2 API. These instances are to be used for an internal application. Can you indentify the storage volume types that CANNOT be used as boot volumes while creating the instances? Select two.",
            "answer": "true",
            "answerText": "Throughput Optimized Hard disk drive (st1) // Cold Hard disk drive (sc1)",
            "srcImg": "",
            "descriptionP": "Solid state drive (SSD) backed volumes optimized for transactional workloads involving frequent read/write operations with small I/O size, where the dominant performance attribute is IOPS. Hard disk drive (HDD) backed volumes optimized for large streaming workloads where throughput (measured in MiB/s) is a better performance measure than IOPS. Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types CANNOT be used as a boot volume, so these two options are correct."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 3 - Randomly!",
            "question": "The IT department is conducting a review of the checklist for tasks related to AWS IAM. Which best practices would you recommend? Select two.",
            "answer": "true",
            "answerText": "Enable AWS Multi-Factor Authentication (AWS MFA) for privileged users // Configure AWS CloudTrail to log all AWS IAM actions",
            "srcImg": "",
            "descriptionP": "As per the AWS best practices, it is better to enable Multi Factor Authentication (MFA) for privileged users via an MFA-enabled mobile device or hardware MFA token. AWS recommends to turn on AWS CloudTrail to log all IAM actions for monitoring and audit purposes."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 4 - Randomly!",
            "question": "A company uses DynamoDB as a data store for various kinds of customer data. Some of these use-cases require a high request rate, low predictable latency, and reliability. The company wants to add a caching layer to support high read volumes.Which of the following AWS services would you recommend as a caching layer? Select two.",
            "answer": "true",
            "answerText": "Amazon ElastiCache // Amazon DynamoDB Accelerator (DAX)",
            "srcImg": "",
            "descriptionP": "Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache for DynamoDB that delivers up to a 10x performance improvement â€“ from milliseconds to microseconds â€“ even at millions of requests per second. DAX does all the heavy lifting required to add in-memory acceleration to your DynamoDB tables, without requiring developers to manage cache invalidation, data population, or cluster management. Amazon ElastiCache for Memcached is an ideal front-end for data stores like Amazon RDS or Amazon DynamoDB, providing a high-performance middle tier for applications with extremely high request rates and/or low latency requirements."
        },
        {
            "title": "ðŸ† Wellcome!!! Deep in the Content and Lost in the Knowledge - Resolution 5 - Randomly!",
            "question": "The company has defined different retention periods for different objects present in the S3, but the retention rules do not seem to work as expected. Which of the following options represent a valid configuration for setting up retention periods for objects. Select two.",
            "answer": "true",
            "answerText": "Different versions of a single object can have different retention modes and periods // When you apply a retention period to an object version explicity, you specify a Retain Until Date for the object version",
            "srcImg": "",
            "descriptionP": "You can place a retention period on an object version either explicitly or through a bucket default setting. When you apply a retention period to an object version explicitly, you specify a Retain Until Date for the object version. Amazon S3 stores the Retain Until Date setting in the object version's metadata and protects the object version until the retention period expires. Like all other Object Lock settings, retention periods apply to individual object versions. Different versions of a single object can have different retention modes and periods."
        }
    ],
    "multiOptions": [
        {
            "option1": "S3 One Zone-IA => S3 Standard-IA.",
            "option2": "S3 Intelligent-Tiering => S3 Standard.",
            "option3": "S3 Standard => S3 Intelligent-Tiering.",
            "option4": "S3 Standard-IA => S3 Intelligent-Tiering.",
            "option5": "S3 Standard-IA => S3 One Zone-IA."  
        }, 
        {
            "option1": "Cold Hard Disk Drive (sc1).",
            "option2": "Throughput Optimized Hard disk Drive (st1).",
            "option3": "Instance Store.",
            "option4": "General Purpose Solid State Drive (gp2).",
            "option5": "Provisioned IOPS Solid State Drive."  
        },
        {
            "option1": "Enable AWS MFA for privileged users.",
            "option2": "Configure AWS CloudTrail to log all AWS IAM actions.",
            "option3": "Use user credentials to provide access specific permissions for EC2 instances.",
            "option4": "Create a minimum number of accounts and share these account credentials among employees.",
            "option5": "Grant maximum privileges to avoid assigning privileges again."  
        },
        {
            "option1": "DynamoDB Accelerator (DAX).",
            "option2": "ElastiCache.",
            "option3": "OpenSearch Service.",
            "option4": "Redshift.",
            "option5": "RDS."
        },
        {
            "option1": "Different versions of a single object can have different retention modes and periods.",
            "option2": "When you apply a retention period to an object version explicity, you specify a Retain Until Date for the object version.",
            "option3": "You cannot place a retention period on an object version through a bucket default setting.",
            "option4": "When you use bucket default setting, you specify a Retain Until Date for the object version.",
            "option5": "The bucket default settings will override any explicit retention mode or period you request on an object version."  
        }
    ]
}
